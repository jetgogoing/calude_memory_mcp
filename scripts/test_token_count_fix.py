#!/usr/bin/env python3
"""
æµ‹è¯•token_countå­—æ®µä¿®å¤
éªŒè¯MemoryUnitModelçš„token_countå­—æ®µæ˜¯å¦å¯ä»¥æ­£å¸¸è®¿é—®å’Œä½¿ç”¨
"""

import sys
import uuid
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/home/jetgogoing/claude_memory/src')

try:
    from claude_memory.models.data_models import MemoryUnitModel, MemoryUnitType
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)

def test_memory_unit_token_count():
    """æµ‹è¯•MemoryUnitModelçš„token_countå­—æ®µ"""
    print("=" * 60)
    print("æµ‹è¯•MemoryUnitModelçš„token_countå­—æ®µ")
    print("=" * 60)
    
    try:
        # åˆ›å»ºMemoryUnitModelå®ä¾‹
        memory_unit = MemoryUnitModel(
            id=str(uuid.uuid4()),
            project_id="test_project",
            conversation_id=str(uuid.uuid4()),
            unit_type=MemoryUnitType.CONVERSATION,
            title="æµ‹è¯•è®°å¿†å•å…ƒ",
            summary="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç”¨çš„è®°å¿†å•å…ƒæ‘˜è¦",
            content="è¿™æ˜¯æµ‹è¯•è®°å¿†å•å…ƒçš„å†…å®¹ï¼Œç”¨äºéªŒè¯token_countå­—æ®µåŠŸèƒ½ã€‚",
            keywords=["æµ‹è¯•", "token_count", "ä¿®å¤"],
            relevance_score=0.85,
            token_count=42  # è®¾ç½®tokenè®¡æ•°
        )
        
        print("âœ… æˆåŠŸåˆ›å»ºMemoryUnitModelå®ä¾‹")
        
        # æµ‹è¯•token_countå­—æ®µè®¿é—®
        print(f"ğŸ“Š Token Count: {memory_unit.token_count}")
        
        # æµ‹è¯•å­—æ®µä¿®æ”¹
        memory_unit.token_count = 100
        print(f"ğŸ“Š æ›´æ–°åçš„Token Count: {memory_unit.token_count}")
        
        # æµ‹è¯•å­—æ®µèµ‹å€¼ï¼ˆæ¨¡æ‹Ÿsemantic_compressorä¸­çš„ä½¿ç”¨ï¼‰
        calculated_tokens = len(memory_unit.content.split())  # ç®€å•çš„tokenè®¡ç®—
        memory_unit.token_count = calculated_tokens
        print(f"ğŸ“Š è®¡ç®—åçš„Token Count: {memory_unit.token_count}")
        
        # éªŒè¯æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
        required_fields = [
            'id', 'project_id', 'conversation_id', 'unit_type', 
            'title', 'summary', 'content', 'token_count'
        ]
        
        missing_fields = []
        for field in required_fields:
            if not hasattr(memory_unit, field):
                missing_fields.append(field)
        
        if missing_fields:
            print(f"âŒ ç¼ºå¤±å­—æ®µ: {missing_fields}")
            return False
        else:
            print("âœ… æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨")
        
        # æµ‹è¯•æ¨¡å‹è½¬æ¢ä¸ºå­—å…¸
        model_dict = memory_unit.model_dump()
        if 'token_count' in model_dict:
            print(f"âœ… model_dump()åŒ…å«token_count: {model_dict['token_count']}")
        else:
            print("âŒ model_dump()ä¸åŒ…å«token_countå­—æ®µ")
            return False
        
        print("\nğŸ‰ æ‰€æœ‰token_countå­—æ®µæµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_field_consistency():
    """æµ‹è¯•å­—æ®µä¸€è‡´æ€§ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•MemoryUnitModelå­—æ®µä¸€è‡´æ€§")
    print("=" * 60)
    
    try:
        # åˆ›å»ºå®ä¾‹å¹¶æ£€æŸ¥å…³é”®å­—æ®µ
        memory_unit = MemoryUnitModel(
            conversation_id=str(uuid.uuid4()),
            unit_type=MemoryUnitType.DOCUMENTATION,
            title="å­—æ®µæµ‹è¯•",
            summary="æµ‹è¯•å­—æ®µä¸€è‡´æ€§",
            content="æµ‹è¯•å†…å®¹"
        )
        
        # æ£€æŸ¥æ–°æ·»åŠ çš„å­—æ®µ
        essential_fields = {
            'token_count': int,
            'is_active': bool,
            'keywords': list,  # ç°åœ¨æ˜¯Optional[List[str]]ï¼Œå¯ä»¥æ˜¯Noneæˆ–list
        }
        
        all_good = True
        for field_name, expected_type in essential_fields.items():
            if hasattr(memory_unit, field_name):
                field_value = getattr(memory_unit, field_name)
                if field_name == 'keywords' and field_value is None:
                    # keywordså­—æ®µç°åœ¨æ˜¯å¯é€‰çš„ï¼ŒNoneæ˜¯æœ‰æ•ˆå€¼
                    print(f"âœ… {field_name}: None (å¯é€‰å­—æ®µ)")
                elif isinstance(field_value, expected_type):
                    print(f"âœ… {field_name}: {field_value} ({type(field_value).__name__})")
                else:
                    print(f"âŒ {field_name}: ç±»å‹ä¸åŒ¹é…ï¼ŒæœŸæœ›{expected_type}ï¼Œå®é™…{type(field_value)}")
                    all_good = False
            else:
                print(f"âŒ ç¼ºå°‘å­—æ®µ: {field_name}")
                all_good = False
        
        if all_good:
            print("\nâœ… å­—æ®µä¸€è‡´æ€§æµ‹è¯•é€šè¿‡ï¼")
            return True
        else:
            print("\nâŒ å­—æ®µä¸€è‡´æ€§æµ‹è¯•å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ å­—æ®µä¸€è‡´æ€§æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("Claude Memory MCP Service - Token Countä¿®å¤æµ‹è¯•")
    print("æ—¶é—´:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    
    # è¿è¡Œæµ‹è¯•
    test1_passed = test_memory_unit_token_count()
    test2_passed = test_field_consistency()
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    print(f"Token Countå­—æ®µæµ‹è¯•: {'âœ… é€šè¿‡' if test1_passed else 'âŒ å¤±è´¥'}")
    print(f"å­—æ®µä¸€è‡´æ€§æµ‹è¯•: {'âœ… é€šè¿‡' if test2_passed else 'âŒ å¤±è´¥'}")
    
    if test1_passed and test2_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¿®å¤æˆåŠŸã€‚")
        print("\nä¸‹ä¸€æ­¥å»ºè®®:")
        print("1. é‡å¯Claude Memory APIæœåŠ¡å™¨")
        print("2. è¿è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•")
        print("3. éªŒè¯semantic_compressoråœ¨å®é™…åœºæ™¯ä¸­çš„å·¥ä½œæƒ…å†µ")
        sys.exit(0)
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¿®å¤ã€‚")
        sys.exit(1)