#!/usr/bin/env python3
"""
æ·±åº¦éªŒè¯ Claude Memory ç³»ç»Ÿçš„æ¨¡å‹é…ç½®ä¸€è‡´æ€§
ç¡®ä¿æ‰€æœ‰æ¨¡å—ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Tuple, Any
import asyncio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))


class ModelConfigurationVerifier:
    """æ¨¡å‹é…ç½®éªŒè¯å™¨"""
    
    def __init__(self):
        self.issues = []
        self.warnings = []
        self.successes = []
        
        # ç”¨æˆ·æŒ‡å®šçš„æ­£ç¡®é…ç½®
        self.expected_config = {
            # åµŒå…¥å’Œé‡æ’åºæ¨¡å‹ (SiliconFlow)
            'embedding_model': 'Qwen/Qwen3-Embedding-8B',
            'rerank_model': 'Qwen/Qwen3-Reranker-8B',
            
            # Mini LLM æ¨¡å‹ (ä¼˜å…ˆé¡ºåº: siliconflow â†’ gemini â†’ openrouter)
            'mini_llm_models': {
                'siliconflow': 'deepseek-ai/DeepSeek-V2.5',
                'gemini': 'gemini-2.5-flash',
                'openrouter': 'deepseek/deepseek-chat-v3-0324'
            },
            'provider_priority': ['siliconflow', 'gemini', 'openrouter'],
            
            # æä¾›å•†çš„å¯ç”¨æ¨¡å‹
            'provider_models': {
                'siliconflow': [
                    'deepseek-ai/DeepSeek-V2.5',
                    'deepseek-ai/DeepSeek-V3',
                    'Qwen/Qwen3-Embedding-8B',
                    'Qwen/Qwen3-Reranker-8B',
                    'Qwen/Qwen2.5-1.5B-Instruct'
                ],
                'gemini': [
                    'gemini-2.5-pro',
                    'gemini-2.5-flash',
                    'text-embedding-004'
                ],
                'openrouter': [
                    'deepseek/deepseek-chat-v3-0324',
                    'anthropic/claude-3.5-sonnet',
                    'openai/gpt-4'
                ]
            }
        }
    
    def verify_env_files(self):
        """éªŒè¯æ‰€æœ‰ç¯å¢ƒå˜é‡æ–‡ä»¶çš„ä¸€è‡´æ€§"""
        print("\n=== 1. éªŒè¯ç¯å¢ƒå˜é‡æ–‡ä»¶é…ç½® ===\n")
        
        env_files = ['.env', '.env.example', '.env.docker.example']
        required_vars = {
            'SILICONFLOW_API_KEY': 'SiliconFlow APIå¯†é’¥',
            'GEMINI_API_KEY': 'Gemini APIå¯†é’¥',
            'OPENROUTER_API_KEY': 'OpenRouter APIå¯†é’¥',
            'DEFAULT_EMBEDDING_MODEL': 'Qwen/Qwen3-Embedding-8B',
            'DEFAULT_RERANK_MODEL': 'Qwen/Qwen3-Reranker-8B',
            'DEFAULT_LIGHT_MODEL': 'deepseek-ai/DeepSeek-V2.5',
            'MINI_LLM_ENABLED': 'true',
            'MINI_LLM_PROVIDER_PRIORITY': 'siliconflow,gemini,openrouter',
            'MEMORY_COMPRESSION_MODEL': 'deepseek-ai/DeepSeek-V2.5',
            'MEMORY_FUSER_MODEL': 'deepseek-ai/DeepSeek-V2.5'
        }
        
        for env_file in env_files:
            env_path = Path(env_file)
            if not env_path.exists():
                self.warnings.append(f"ç¯å¢ƒæ–‡ä»¶ä¸å­˜åœ¨: {env_file}")
                continue
            
            print(f"æ£€æŸ¥ {env_file}:")
            env_vars = {}
            
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        env_vars[key.strip()] = value.strip()
            
            # æ£€æŸ¥å¿…éœ€çš„å˜é‡
            for var, expected in required_vars.items():
                if var in env_vars:
                    actual = env_vars[var]
                    if var.endswith('_API_KEY'):
                        if actual:
                            print(f"  âœ… {var}: å·²è®¾ç½®")
                        else:
                            self.issues.append(f"{env_file}: {var} ä¸ºç©º")
                            print(f"  âŒ {var}: æœªè®¾ç½®")
                    else:
                        if actual == expected:
                            print(f"  âœ… {var}: {actual}")
                        else:
                            self.issues.append(f"{env_file}: {var} åº”ä¸º '{expected}'ï¼Œå®é™…ä¸º '{actual}'")
                            print(f"  âŒ {var}: æœŸæœ› '{expected}'ï¼Œå®é™… '{actual}'")
                else:
                    self.issues.append(f"{env_file}: ç¼ºå°‘ {var}")
                    print(f"  âŒ {var}: ç¼ºå¤±")
    
    def verify_settings_py(self):
        """éªŒè¯ settings.py ä¸­çš„é…ç½®"""
        print("\n=== 2. éªŒè¯ settings.py é…ç½® ===\n")
        
        try:
            from claude_memory.config.settings import get_settings
            settings = get_settings()
            
            # æ£€æŸ¥æ¨¡å‹è®¾ç½®
            checks = [
                ('é»˜è®¤åµŒå…¥æ¨¡å‹', settings.models.default_embedding_model, self.expected_config['embedding_model']),
                ('é»˜è®¤é‡æ’åºæ¨¡å‹', settings.models.default_rerank_model, self.expected_config['rerank_model']),
                ('é»˜è®¤è½»é‡æ¨¡å‹', settings.models.default_light_model, self.expected_config['mini_llm_models']['siliconflow']),
                ('Mini LLMå¯ç”¨', settings.mini_llm.enabled, True),
                ('æä¾›å•†ä¼˜å…ˆçº§', settings.mini_llm.provider_priority, 'siliconflow,gemini,openrouter'),
                ('SiliconFlowæ¨¡å‹', settings.mini_llm.siliconflow_model, self.expected_config['mini_llm_models']['siliconflow']),
                ('Geminiæ¨¡å‹', settings.mini_llm.gemini_model, self.expected_config['mini_llm_models']['gemini']),
                ('OpenRouteræ¨¡å‹', settings.mini_llm.openrouter_model, self.expected_config['mini_llm_models']['openrouter'])
            ]
            
            for name, actual, expected in checks:
                if str(actual) == str(expected):
                    print(f"âœ… {name}: {actual}")
                    self.successes.append(f"settings.py: {name} é…ç½®æ­£ç¡®")
                else:
                    print(f"âŒ {name}: æœŸæœ› '{expected}'ï¼Œå®é™… '{actual}'")
                    self.issues.append(f"settings.py: {name} é…ç½®é”™è¯¯")
            
            # æ£€æŸ¥APIå¯†é’¥
            api_keys = [
                ('SiliconFlow', settings.models.siliconflow_api_key),
                ('Gemini', settings.models.gemini_api_key),
                ('OpenRouter', settings.models.openrouter_api_key)
            ]
            
            print("\nAPIå¯†é’¥çŠ¶æ€:")
            for name, key in api_keys:
                if key:
                    print(f"âœ… {name} APIå¯†é’¥: å·²é…ç½®")
                else:
                    print(f"âŒ {name} APIå¯†é’¥: æœªé…ç½®")
                    self.issues.append(f"settings.py: {name} APIå¯†é’¥æœªé…ç½®")
                    
        except Exception as e:
            self.issues.append(f"æ— æ³•åŠ è½½ settings.py: {str(e)}")
            print(f"âŒ åŠ è½½è®¾ç½®å¤±è´¥: {str(e)}")
    
    def verify_model_manager(self):
        """éªŒè¯ ModelManager ä¸­çš„æ¨¡å‹æ˜ å°„"""
        print("\n=== 3. éªŒè¯ ModelManager æ¨¡å‹æ˜ å°„ ===\n")
        
        try:
            from claude_memory.utils.model_manager import ModelManager
            model_manager = ModelManager()
            
            # æ£€æŸ¥æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹æ˜¯å¦éƒ½æœ‰æ˜ å°„
            required_models = [
                'Qwen/Qwen3-Embedding-8B',
                'Qwen/Qwen3-Reranker-8B',
                'deepseek-ai/DeepSeek-V2.5',
                'gemini-2.5-flash',
                'gemini-2.5-pro',
                'deepseek/deepseek-chat-v3-0324'
            ]
            
            print("æ¨¡å‹æ˜ å°„æ£€æŸ¥:")
            for model in required_models:
                if model in model_manager.model_provider_map:
                    provider = model_manager.model_provider_map[model]
                    print(f"âœ… {model} -> {provider}")
                else:
                    print(f"âŒ {model}: æœªæ‰¾åˆ°æ˜ å°„")
                    self.issues.append(f"ModelManager: {model} æœªæ˜ å°„åˆ°ä»»ä½•æä¾›å•†")
            
            # æ£€æŸ¥æä¾›å•†é…ç½®
            print("\næä¾›å•†é…ç½®:")
            for provider, config in model_manager.providers.items():
                api_key_status = "å·²é…ç½®" if config['api_key'] else "æœªé…ç½®"
                print(f"{provider}: APIå¯†é’¥ {api_key_status}")
                print(f"  æ”¯æŒçš„æ¨¡å‹: {', '.join(config['models'])}")
                
        except Exception as e:
            self.issues.append(f"æ— æ³•åŠ è½½ ModelManager: {str(e)}")
            print(f"âŒ åŠ è½½ ModelManager å¤±è´¥: {str(e)}")
    
    def verify_semantic_compressor(self):
        """éªŒè¯ SemanticCompressor ä¸­çš„æ¨¡å‹é…ç½®"""
        print("\n=== 4. éªŒè¯ SemanticCompressor é…ç½® ===\n")
        
        try:
            from claude_memory.processors.semantic_compressor import SemanticCompressor
            compressor = SemanticCompressor()
            
            print("è½»é‡çº§æ¨¡å‹:")
            for model in compressor.light_models:
                print(f"  - {model}")
                if model == 'deepseek-r1':
                    self.warnings.append("SemanticCompressor: 'deepseek-r1' å¯èƒ½éœ€è¦æ˜ å°„åˆ°æ­£ç¡®çš„æä¾›å•†")
            
            print("\né‡é‡çº§æ¨¡å‹:")
            for model in compressor.heavy_models:
                print(f"  - {model}")
                if model == 'claude-3.5-sonnet':
                    self.warnings.append("SemanticCompressor: 'claude-3.5-sonnet' éœ€è¦å®Œæ•´çš„æ¨¡å‹åç§°")
                    
        except Exception as e:
            self.issues.append(f"æ— æ³•åŠ è½½ SemanticCompressor: {str(e)}")
            print(f"âŒ åŠ è½½ SemanticCompressor å¤±è´¥: {str(e)}")
    
    async def verify_mini_llm_manager(self):
        """éªŒè¯ MiniLLMManager çš„è¿è¡Œæ—¶é…ç½®"""
        print("\n=== 5. éªŒè¯ MiniLLMManager è¿è¡Œæ—¶é…ç½® ===\n")
        
        try:
            from claude_memory.llm.mini_llm_manager import MiniLLMManager, TaskType
            manager = MiniLLMManager()
            await manager.initialize()
            
            # æ£€æŸ¥è·¯ç”±è§„åˆ™
            print("ä»»åŠ¡è·¯ç”±è§„åˆ™:")
            for task_type, rules in manager.task_router.routing_rules.items():
                if task_type == TaskType.COMPLETION:
                    print(f"\n{task_type}:")
                    print(f"  é¦–é€‰æ¨¡å‹: {rules.get('preferred_model')}")
                    print(f"  æä¾›å•†ä¼˜å…ˆçº§: {rules.get('provider_priority')}")
                    
                    # éªŒè¯COMPLETIONä»»åŠ¡ä½¿ç”¨æ­£ç¡®çš„é…ç½®
                    expected_priority = self.expected_config['provider_priority']
                    actual_priority = rules.get('provider_priority', [])
                    
                    if actual_priority == expected_priority:
                        self.successes.append("MiniLLMManager: COMPLETIONä»»åŠ¡ä¼˜å…ˆçº§é…ç½®æ­£ç¡®")
                    else:
                        self.issues.append(f"MiniLLMManager: COMPLETIONä»»åŠ¡ä¼˜å…ˆçº§é”™è¯¯ - æœŸæœ›{expected_priority}ï¼Œå®é™…{actual_priority}")
            
            # æ£€æŸ¥å¯ç”¨çš„æä¾›å•†
            print("\nå·²åˆå§‹åŒ–çš„æä¾›å•†:")
            for provider, instance in manager.providers.items():
                is_available = await instance.is_available()
                status = "å¯ç”¨" if is_available else "ä¸å¯ç”¨"
                print(f"  {provider}: {status}")
                if not is_available:
                    self.warnings.append(f"MiniLLMManager: {provider} æä¾›å•†ä¸å¯ç”¨")
            
            await manager.cleanup()
            
        except Exception as e:
            self.issues.append(f"æ— æ³•éªŒè¯ MiniLLMManager: {str(e)}")
            print(f"âŒ éªŒè¯ MiniLLMManager å¤±è´¥: {str(e)}")
    
    async def verify_api_connectivity(self):
        """éªŒè¯APIè¿æ¥æ€§"""
        print("\n=== 6. éªŒè¯APIè¿æ¥æ€§ ===\n")
        
        try:
            from claude_memory.utils.model_manager import ModelManager
            from claude_memory.llm.mini_llm_manager import (
                MiniLLMManager, MiniLLMRequest, TaskType
            )
            
            # æµ‹è¯•åµŒå…¥ç”Ÿæˆ
            print("æµ‹è¯•åµŒå…¥ç”Ÿæˆ (Qwen3-Embedding-8B):")
            model_manager = ModelManager()
            await model_manager.initialize()
            
            try:
                response = await model_manager.generate_embedding(
                    model="Qwen/Qwen3-Embedding-8B",
                    text="æµ‹è¯•æ–‡æœ¬"
                )
                print(f"âœ… åµŒå…¥ç»´åº¦: {response.dimension}")
                self.successes.append("APIè¿æ¥: Qwen3åµŒå…¥ç”ŸæˆæˆåŠŸ")
            except Exception as e:
                print(f"âŒ åµŒå…¥ç”Ÿæˆå¤±è´¥: {str(e)}")
                self.issues.append(f"APIè¿æ¥: Qwen3åµŒå…¥ç”Ÿæˆå¤±è´¥ - {str(e)}")
            
            # æµ‹è¯•Mini LLM
            print("\næµ‹è¯•Mini LLM (DeepSeek-V2.5):")
            mini_llm = MiniLLMManager()
            await mini_llm.initialize()
            
            try:
                request = MiniLLMRequest(
                    task_type=TaskType.COMPLETION,
                    input_text="Hello, this is a test.",
                    parameters={"max_tokens": 50}
                )
                response = await mini_llm.process(request)
                print(f"âœ… ä½¿ç”¨æ¨¡å‹: {response.model_used}")
                print(f"âœ… æä¾›å•†: {response.provider}")
                self.successes.append(f"APIè¿æ¥: Mini LLMé€šè¿‡{response.provider}æˆåŠŸ")
            except Exception as e:
                print(f"âŒ Mini LLMè°ƒç”¨å¤±è´¥: {str(e)}")
                self.issues.append(f"APIè¿æ¥: Mini LLMè°ƒç”¨å¤±è´¥ - {str(e)}")
            
            await model_manager.close()
            await mini_llm.cleanup()
            
        except Exception as e:
            self.issues.append(f"APIè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
            print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
    
    def generate_fix_script(self):
        """ç”Ÿæˆä¿®å¤è„šæœ¬"""
        if not self.issues:
            return
        
        print("\n=== ç”Ÿæˆä¿®å¤è„šæœ¬ ===\n")
        
        fix_script = """#!/bin/bash
# Claude Memory æ¨¡å‹é…ç½®ä¿®å¤è„šæœ¬
# ç”Ÿæˆæ—¶é—´: $(date)

echo "å¼€å§‹ä¿®å¤æ¨¡å‹é…ç½®..."

# 1. æ›´æ–°ç¯å¢ƒå˜é‡æ–‡ä»¶
update_env_file() {
    local file=$1
    echo "æ›´æ–° $file..."
    
    # å¤‡ä»½åŸæ–‡ä»¶
    cp $file ${file}.backup.$(date +%Y%m%d_%H%M%S)
    
    # æ›´æ–°æ¨¡å‹é…ç½®
    sed -i 's/DEFAULT_EMBEDDING_MODEL=.*/DEFAULT_EMBEDDING_MODEL=Qwen\\/Qwen3-Embedding-8B/g' $file
    sed -i 's/DEFAULT_RERANK_MODEL=.*/DEFAULT_RERANK_MODEL=Qwen\\/Qwen3-Reranker-8B/g' $file
    sed -i 's/DEFAULT_LIGHT_MODEL=.*/DEFAULT_LIGHT_MODEL=deepseek-ai\\/DeepSeek-V2.5/g' $file
    sed -i 's/MINI_LLM_PROVIDER_PRIORITY=.*/MINI_LLM_PROVIDER_PRIORITY=siliconflow,gemini,openrouter/g' $file
    sed -i 's/MEMORY_COMPRESSION_MODEL=.*/MEMORY_COMPRESSION_MODEL=deepseek-ai\\/DeepSeek-V2.5/g' $file
    sed -i 's/MEMORY_FUSER_MODEL=.*/MEMORY_FUSER_MODEL=deepseek-ai\\/DeepSeek-V2.5/g' $file
}

# æ›´æ–°æ‰€æœ‰ç¯å¢ƒæ–‡ä»¶
for env_file in .env .env.example .env.docker.example; do
    if [ -f "$env_file" ]; then
        update_env_file $env_file
    fi
done

echo "âœ… ç¯å¢ƒå˜é‡æ–‡ä»¶æ›´æ–°å®Œæˆ"

# 2. ä¿®å¤Pythonä»£ç ä¸­çš„æ¨¡å‹æ˜ å°„
echo "ä¿®å¤æ¨¡å‹æ˜ å°„..."

# åœ¨model_manager.pyä¸­æ·»åŠ ç¼ºå¤±çš„æ˜ å°„
python3 << 'EOF'
import re
from pathlib import Path

model_manager_path = Path("src/claude_memory/utils/model_manager.py")
content = model_manager_path.read_text()

# ç¡®ä¿æ‰€æœ‰æ¨¡å‹éƒ½æœ‰æ­£ç¡®çš„æ˜ å°„
mappings_to_add = {
    "'deepseek-r1': 'openrouter',": "# deepseek-r1 æ˜ å°„åˆ° openrouter",
    "'claude-3.5-sonnet': 'openrouter',": "# ç®€çŸ­åç§°æ˜ å°„"
}

for mapping, comment in mappings_to_add.items():
    if mapping not in content:
        # åœ¨model_provider_mapå­—å…¸ä¸­æ·»åŠ 
        content = re.sub(
            r"(self\.model_provider_map = {[^}]+)",
            f"\\1\\n            {mapping}  {comment}",
            content,
            flags=re.DOTALL
        )

model_manager_path.write_text(content)
print("âœ… model_manager.py æ›´æ–°å®Œæˆ")
EOF

echo "âœ… æ‰€æœ‰ä¿®å¤å®Œæˆï¼"
echo ""
echo "è¯·é‡æ–°å¯åŠ¨æœåŠ¡ä»¥åº”ç”¨æ›´æ”¹ï¼š"
echo "  docker-compose restart"
echo "  æˆ–"
echo "  python -m claude_memory"
"""
        
        with open('fix_model_configurations.sh', 'w') as f:
            f.write(fix_script)
        
        os.chmod('fix_model_configurations.sh', 0o755)
        print("å·²ç”Ÿæˆä¿®å¤è„šæœ¬: fix_model_configurations.sh")
        print("æ‰§è¡Œå‘½ä»¤: ./fix_model_configurations.sh")
    
    def print_summary(self):
        """æ‰“å°éªŒè¯æ‘˜è¦"""
        print("\n" + "="*60)
        print("éªŒè¯æ‘˜è¦")
        print("="*60)
        
        print(f"\nâœ… æˆåŠŸé¡¹: {len(self.successes)}")
        for success in self.successes[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  - {success}")
        if len(self.successes) > 5:
            print(f"  ... è¿˜æœ‰ {len(self.successes) - 5} é¡¹")
        
        print(f"\nâš ï¸  è­¦å‘Šé¡¹: {len(self.warnings)}")
        for warning in self.warnings:
            print(f"  - {warning}")
        
        print(f"\nâŒ é—®é¢˜é¡¹: {len(self.issues)}")
        for issue in self.issues:
            print(f"  - {issue}")
        
        if not self.issues:
            print("\nğŸ‰ æ­å–œï¼æ‰€æœ‰æ¨¡å‹é…ç½®éƒ½å·²ç»Ÿä¸€ï¼Œç¬¦åˆè¦æ±‚ã€‚")
        else:
            print("\nâš ï¸  å‘ç°é…ç½®ä¸ä¸€è‡´ï¼Œè¯·è¿è¡Œç”Ÿæˆçš„ä¿®å¤è„šæœ¬ã€‚")


async def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("Claude Memory æ¨¡å‹é…ç½®æ·±åº¦éªŒè¯")
    print("="*60)
    
    verifier = ModelConfigurationVerifier()
    
    # æ‰§è¡Œæ‰€æœ‰éªŒè¯
    verifier.verify_env_files()
    verifier.verify_settings_py()
    verifier.verify_model_manager()
    verifier.verify_semantic_compressor()
    await verifier.verify_mini_llm_manager()
    await verifier.verify_api_connectivity()
    
    # æ‰“å°æ‘˜è¦
    verifier.print_summary()
    
    # ç”Ÿæˆä¿®å¤è„šæœ¬
    if verifier.issues:
        verifier.generate_fix_script()


if __name__ == "__main__":
    asyncio.run(main())