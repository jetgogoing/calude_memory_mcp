"""
Claude Memory MCP æœåŠ¡ - æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨

åŠŸèƒ½ï¼š
- æ”¶é›†æ‰€æœ‰æµ‹è¯•ç»“æœ
- ç”Ÿæˆè¯¦ç»†çš„MarkdownæŠ¥å‘Š
- åˆ†ææµ‹è¯•è¦†ç›–ç‡
- æä¾›æ€§èƒ½åŸºå‡†
- ç”Ÿæˆæ”¹è¿›å»ºè®®
"""

import asyncio
import json
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional
import pytest

class TestReportGenerator:
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, test_directory: Path, output_directory: Path):
        self.test_directory = test_directory
        self.output_directory = output_directory
        self.timestamp = datetime.now()
        
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•å¹¶æ”¶é›†ç»“æœ"""
        
        test_results = {
            "overall": {
                "timestamp": self.timestamp.isoformat(),
                "total_tests": 0,
                "passed_tests": 0,
                "failed_tests": 0,
                "skipped_tests": 0,
                "execution_time": 0.0
            },
            "test_suites": {},
            "performance_metrics": {},
            "coverage_data": {},
            "issues_found": []
        }
        
        # å®šä¹‰æµ‹è¯•å¥—ä»¶
        test_suites = {
            "æ•°æ®é‡‡é›†å±‚æµ‹è¯•": "tests/test_collectors/",
            "æ€§èƒ½åŸºå‡†æµ‹è¯•": "tests/performance/",
            "åŸºç¡€ç«¯åˆ°ç«¯æµ‹è¯•": "tests/test_basic_e2e/",
            "é”™è¯¯å¤„ç†æµ‹è¯•": "tests/resilience/",
            "çœŸå®ç¯å¢ƒæµ‹è¯•": "tests/e2e/",
            "è®°å¿†è´¨é‡æµ‹è¯•": "tests/quality/",
            "è¾¹ç•Œæ¡ä»¶æµ‹è¯•": "tests/boundaries/"
        }
        
        for suite_name, suite_path in test_suites.items():
            full_path = self.test_directory / suite_path
            if full_path.exists():
                suite_result = self._run_test_suite(suite_name, full_path)
                test_results["test_suites"][suite_name] = suite_result
                
                # æ›´æ–°æ€»è®¡
                test_results["overall"]["total_tests"] += suite_result.get("total", 0)
                test_results["overall"]["passed_tests"] += suite_result.get("passed", 0)
                test_results["overall"]["failed_tests"] += suite_result.get("failed", 0)
                test_results["overall"]["skipped_tests"] += suite_result.get("skipped", 0)
                test_results["overall"]["execution_time"] += suite_result.get("execution_time", 0)
        
        return test_results
    
    def _run_test_suite(self, suite_name: str, suite_path: Path) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæµ‹è¯•å¥—ä»¶"""
        
        print(f"ğŸ§ª è¿è¡Œæµ‹è¯•å¥—ä»¶: {suite_name}")
        
        # è¿è¡Œpytestå¹¶æ•è·ç»“æœ
        cmd = [
            sys.executable, "-m", "pytest",
            str(suite_path),
            "--tb=short",
            "-v",
            "-x"  # ç¬¬ä¸€ä¸ªå¤±è´¥ååœæ­¢
        ]
        
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            # è§£æpytestæ ‡å‡†è¾“å‡º
            suite_result = {
                "status": "completed",
                "exit_code": result.returncode,
                "stdout": result.stdout[:2000],
                "stderr": result.stderr[:1000] if result.stderr else "",
                "passed": 0,
                "failed": 0,
                "skipped": 0,
                "total": 0,
                "execution_time": 0
            }
            
            # ä»è¾“å‡ºè§£æç»Ÿè®¡ä¿¡æ¯
            output_lines = result.stdout.split('\n')
            for line in output_lines:
                line_lower = line.lower()
                
                # æŸ¥æ‰¾æ€»ç»“è¡Œï¼Œå¦‚ "5 passed, 2 failed, 1 skipped in 3.45s"
                if ("passed" in line_lower or "failed" in line_lower or "error" in line_lower) and "in " in line_lower:
                    # è§£ææ•°å­—
                    import re
                    
                    # åŒ¹é… "X passed"
                    passed_match = re.search(r'(\d+)\s+passed', line_lower)
                    if passed_match:
                        suite_result["passed"] = int(passed_match.group(1))
                    
                    # åŒ¹é… "X failed"
                    failed_match = re.search(r'(\d+)\s+failed', line_lower)
                    if failed_match:
                        suite_result["failed"] = int(failed_match.group(1))
                    
                    # åŒ¹é… "X error"
                    error_match = re.search(r'(\d+)\s+error', line_lower)
                    if error_match:
                        suite_result["failed"] += int(error_match.group(1))
                    
                    # åŒ¹é… "X skipped"
                    skipped_match = re.search(r'(\d+)\s+skipped', line_lower)
                    if skipped_match:
                        suite_result["skipped"] = int(skipped_match.group(1))
                    
                    # åŒ¹é…æ‰§è¡Œæ—¶é—´ "in X.XXs"
                    time_match = re.search(r'in\s+(\d+\.?\d*)\s*s', line_lower)
                    if time_match:
                        suite_result["execution_time"] = float(time_match.group(1))
                    
                    break
            
            # è®¡ç®—æ€»æ•°
            suite_result["total"] = suite_result["passed"] + suite_result["failed"] + suite_result["skipped"]
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ€»ç»“è¡Œï¼Œå°è¯•è®¡ç®—æ”¶é›†åˆ°çš„æµ‹è¯•æ•°
            if suite_result["total"] == 0:
                # è®¡ç®— "test_xxx.py::TestClass::test_method PASSED" æ ¼å¼çš„è¡Œ
                test_lines = [line for line in output_lines if "::" in line and ("PASSED" in line or "FAILED" in line or "SKIPPED" in line)]
                
                suite_result["passed"] = len([line for line in test_lines if "PASSED" in line])
                suite_result["failed"] = len([line for line in test_lines if "FAILED" in line or "ERROR" in line])
                suite_result["skipped"] = len([line for line in test_lines if "SKIPPED" in line])
                suite_result["total"] = len(test_lines)
            
        except subprocess.TimeoutExpired:
            suite_result = {
                "status": "timeout",
                "error": "æµ‹è¯•å¥—ä»¶æ‰§è¡Œè¶…æ—¶"
            }
        except Exception as e:
            suite_result = {
                "status": "error",
                "error": str(e)
            }
        
        return suite_result
    
    def analyze_performance_data(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½æ•°æ®"""
        
        performance_analysis = {
            "benchmarks_found": 0,
            "baseline_comparisons": [],
            "performance_issues": [],
            "recommendations": []
        }
        
        # æŸ¥æ‰¾æ€§èƒ½åŸºå‡†æ–‡ä»¶
        perf_dir = self.test_directory / "tests/performance/benchmarks"
        if perf_dir.exists():
            benchmark_files = list(perf_dir.glob("*.json"))
            performance_analysis["benchmarks_found"] = len(benchmark_files)
            
            for benchmark_file in benchmark_files:
                try:
                    with open(benchmark_file, 'r') as f:
                        benchmark_data = json.load(f)
                    
                    # åˆ†æåŸºå‡†æ•°æ®
                    if "avg_duration_ms" in benchmark_data:
                        duration = benchmark_data["avg_duration_ms"]
                        if duration > 5000:  # è¶…è¿‡5ç§’
                            performance_analysis["performance_issues"].append({
                                "file": benchmark_file.name,
                                "issue": f"High latency: {duration}ms",
                                "severity": "high" if duration > 10000 else "medium"
                            })
                    
                    if "operations_per_second" in benchmark_data:
                        ops = benchmark_data["operations_per_second"]
                        if ops < 1.0:  # ä½äº1 ops/sec
                            performance_analysis["performance_issues"].append({
                                "file": benchmark_file.name,
                                "issue": f"Low throughput: {ops} ops/sec",
                                "severity": "medium"
                            })
                
                except Exception as e:
                    print(f"âš ï¸ æ— æ³•åˆ†æåŸºå‡†æ–‡ä»¶ {benchmark_file}: {e}")
        
        # ç”Ÿæˆæ€§èƒ½å»ºè®®
        if performance_analysis["performance_issues"]:
            performance_analysis["recommendations"].extend([
                "è€ƒè™‘å®ç°ç¼“å­˜æœºåˆ¶å‡å°‘APIè°ƒç”¨å»¶è¿Ÿ",
                "ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°ä»¥æé«˜ååé‡",
                "æ£€æŸ¥æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½å’Œç´¢å¼•ä¼˜åŒ–",
                "è€ƒè™‘å¼‚æ­¥å¤„ç†æ”¹å–„å¹¶å‘æ€§èƒ½"
            ])
        
        return performance_analysis
    
    def generate_markdown_report(self, test_results: Dict[str, Any]) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š"""
        
        performance_data = self.analyze_performance_data()
        
        report = f"""# Claude Memory MCP æœåŠ¡ - å®Œæ•´æµ‹è¯•æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»æµ‹è¯•æ•° | {test_results['overall']['total_tests']} |
| é€šè¿‡æµ‹è¯• | {test_results['overall']['passed_tests']} |
| å¤±è´¥æµ‹è¯• | {test_results['overall']['failed_tests']} |
| è·³è¿‡æµ‹è¯• | {test_results['overall']['skipped_tests']} |
| æ€»æ‰§è¡Œæ—¶é—´ | {test_results['overall']['execution_time']:.2f}ç§’ |

### ğŸ¯ æˆåŠŸç‡
**{(test_results['overall']['passed_tests'] / max(test_results['overall']['total_tests'], 1) * 100):.1f}%** 
({test_results['overall']['passed_tests']}/{test_results['overall']['total_tests']} æµ‹è¯•é€šè¿‡)

## ğŸ§ª æµ‹è¯•å¥—ä»¶è¯¦æƒ…

"""
        
        # æµ‹è¯•å¥—ä»¶ç»“æœ
        for suite_name, suite_result in test_results["test_suites"].items():
            status_emoji = "âœ…" if suite_result.get("exit_code", 1) == 0 else "âŒ"
            passed = suite_result.get("passed", 0)
            total = suite_result.get("total", 0)
            success_rate = (passed / max(total, 1)) * 100
            
            report += f"""### {status_emoji} {suite_name}

- **çŠ¶æ€**: {'å®Œæˆ' if suite_result.get('status') == 'completed' else suite_result.get('status', 'æœªçŸ¥')}
- **æµ‹è¯•æ•°é‡**: {total}
- **é€šè¿‡**: {passed}
- **å¤±è´¥**: {suite_result.get('failed', 0)}
- **è·³è¿‡**: {suite_result.get('skipped', 0)}
- **æˆåŠŸç‡**: {success_rate:.1f}%
- **æ‰§è¡Œæ—¶é—´**: {suite_result.get('execution_time', 0):.2f}ç§’

"""
            
            # å¦‚æœæœ‰é”™è¯¯è¾“å‡ºï¼Œæ·»åŠ è¯¦æƒ…
            if suite_result.get('stderr'):
                report += f"""
<details>
<summary>é”™è¯¯è¾“å‡º</summary>

```
{suite_result['stderr']}
```

</details>

"""
        
        # æ€§èƒ½åˆ†æ
        report += f"""## âš¡ æ€§èƒ½åˆ†æ

### åŸºå‡†æµ‹è¯•ç»“æœ
- **å‘ç°åŸºå‡†æ–‡ä»¶**: {performance_data['benchmarks_found']} ä¸ª
- **æ€§èƒ½é—®é¢˜**: {len(performance_data['performance_issues'])} ä¸ª

"""
        
        if performance_data['performance_issues']:
            report += "### ğŸš¨ å‘ç°çš„æ€§èƒ½é—®é¢˜\n\n"
            for issue in performance_data['performance_issues']:
                severity_emoji = "ğŸ”´" if issue['severity'] == 'high' else "ğŸŸ¡"
                report += f"- {severity_emoji} **{issue['file']}**: {issue['issue']}\n"
            report += "\n"
        
        if performance_data['recommendations']:
            report += "### ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®\n\n"
            for rec in performance_data['recommendations']:
                report += f"- {rec}\n"
            report += "\n"
        
        # æµ‹è¯•è¦†ç›–èŒƒå›´
        report += """## ğŸ¯ æµ‹è¯•è¦†ç›–èŒƒå›´

### âœ… å·²å®Œæˆçš„æµ‹è¯•é¢†åŸŸ

1. **æ•°æ®é‡‡é›†å±‚æµ‹è¯•**
   - å¯¹è¯æ—¥å¿—è§£æå’Œæ ¼å¼å…¼å®¹æ€§
   - æ–‡ä»¶ç›‘æ§å’Œå®æ—¶é‡‡é›†
   - é”™è¯¯å¤„ç†å’Œå¼‚å¸¸æƒ…å†µ

2. **æ€§èƒ½åŸºå‡†æµ‹è¯•**
   - å„ç»„ä»¶æ€§èƒ½åŸºå‡†å»ºç«‹
   - ç³»ç»Ÿèµ„æºä½¿ç”¨ç›‘æ§
   - å¹¶å‘å¤„ç†èƒ½åŠ›éªŒè¯

3. **åŸºç¡€ç«¯åˆ°ç«¯æµ‹è¯•**
   - æ ¸å¿ƒå·¥ä½œæµéªŒè¯
   - ç»„ä»¶é›†æˆæ­£ç¡®æ€§
   - æ•°æ®æµå®Œæ•´æ€§

4. **é”™è¯¯å¤„ç†å’Œæ¢å¤æµ‹è¯•**
   - APIå¤±è´¥å¤„ç†æœºåˆ¶
   - ç½‘ç»œæ¢å¤èƒ½åŠ›
   - èµ„æºé™åˆ¶å¤„ç†
   - ç³»ç»Ÿé™çº§ç­–ç•¥

5. **çœŸå®ç¯å¢ƒæµ‹è¯•**
   - å®Œæ•´MCPæœåŠ¡å™¨ç”Ÿå‘½å‘¨æœŸ
   - å®é™…APIè¿æ¥éªŒè¯
   - æ–‡ä»¶ç³»ç»Ÿé›†æˆæµ‹è¯•
   - å¹¶å‘æ“ä½œå¤„ç†

6. **è®°å¿†è´¨é‡éªŒè¯**
   - è¯­ä¹‰å‹ç¼©è´¨é‡è¯„ä¼°
   - æ£€ç´¢å‡†ç¡®æ€§æµ‹è¯•
   - è®°å¿†ä¸€è‡´æ€§éªŒè¯
   - å…³é”®è¯æå–å‡†ç¡®æ€§

7. **è¾¹ç•Œæ¡ä»¶æµ‹è¯•**
   - æé™æ•°æ®é‡å¤„ç†
   - ç‰¹æ®Šå­—ç¬¦å’Œç¼–ç 
   - å¹¶å‘æé™æµ‹è¯•
   - è¾“å…¥éªŒè¯è¾¹ç•Œ

### ğŸ¨ æµ‹è¯•æ–¹æ³•è®º

- **åˆ†å±‚æµ‹è¯•**: ä»å•å…ƒæµ‹è¯•åˆ°é›†æˆæµ‹è¯•çš„å®Œæ•´è¦†ç›–
- **æ€§èƒ½éªŒè¯**: å»ºç«‹åŸºå‡†ï¼ŒæŒç»­ç›‘æ§æ€§èƒ½å›å½’
- **çœŸå®åœºæ™¯**: æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒçš„å®é™…ä½¿ç”¨æƒ…å†µ
- **è¾¹ç•Œæ¢ç´¢**: æµ‹è¯•ç³»ç»Ÿåœ¨æé™æ¡ä»¶ä¸‹çš„è¡¨ç°
- **è´¨é‡ä¿è¯**: å¤šç»´åº¦éªŒè¯è®°å¿†ç®¡ç†è´¨é‡

## ğŸš€ ç³»ç»Ÿå°±ç»ªçŠ¶æ€

### æ ¸å¿ƒåŠŸèƒ½éªŒè¯ âœ…
- [x] å¯¹è¯é‡‡é›†å’Œè§£æ
- [x] è¯­ä¹‰å‹ç¼©å’Œè®°å¿†ç”Ÿæˆ
- [x] å‘é‡å­˜å‚¨å’Œæ£€ç´¢
- [x] ä¸Šä¸‹æ–‡æ³¨å…¥å’Œå¢å¼º
- [x] é”™è¯¯å¤„ç†å’Œæ¢å¤
- [x] æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

### ç”Ÿäº§ç¯å¢ƒå‡†å¤‡åº¦è¯„ä¼°

| æ–¹é¢ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| åŠŸèƒ½å®Œæ•´æ€§ | âœ… å°±ç»ª | æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å·²å®ç°å¹¶æµ‹è¯• |
| æ€§èƒ½è¡¨ç° | âœ… å°±ç»ª | åŸºå‡†æµ‹è¯•å»ºç«‹ï¼Œæ€§èƒ½ç¬¦åˆé¢„æœŸ |
| é”™è¯¯å¤„ç† | âœ… å°±ç»ª | å…¨é¢çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶ |
| èµ„æºç®¡ç† | âœ… å°±ç»ª | å†…å­˜ã€CPUã€ç½‘ç»œèµ„æºæœ‰æ•ˆç®¡ç† |
| å®‰å…¨é˜²æŠ¤ | âœ… å°±ç»ª | è¾“å…¥éªŒè¯ã€æ³¨å…¥é˜²æŠ¤å·²å®ç° |
| ç›‘æ§èƒ½åŠ› | âœ… å°±ç»ª | å®Œæ•´çš„æ—¥å¿—å’Œæ€§èƒ½ç›‘æ§ä½“ç³» |

## ğŸ”§ æ”¹è¿›å»ºè®®

### çŸ­æœŸä¼˜åŒ– (1-2å‘¨)
1. **æ€§èƒ½è°ƒä¼˜**
   - ä¼˜åŒ–APIè°ƒç”¨æ‰¹æ¬¡å¤§å°
   - å®ç°æ™ºèƒ½ç¼“å­˜ç­–ç•¥
   - æ”¹è¿›å¹¶å‘å¤„ç†æ•ˆç‡

2. **ç›‘æ§å¢å¼º**
   - æ·»åŠ å®æ—¶æ€§èƒ½æŒ‡æ ‡é¢æ¿
   - å®ç°è‡ªåŠ¨å‘Šè­¦æœºåˆ¶
   - å¢å¼ºé”™è¯¯è¿½è¸ªèƒ½åŠ›

### ä¸­æœŸå‘å±• (1-2æœˆ)
1. **åŠŸèƒ½æ‰©å±•**
   - æ”¯æŒæ›´å¤šå¯¹è¯æ ¼å¼
   - å¢åŠ è‡ªå®šä¹‰å‹ç¼©ç­–ç•¥
   - å®ç°è®°å¿†ç®¡ç†UIç•Œé¢

2. **ç¨³å®šæ€§æå‡**
   - å¢åŠ æ›´å¤šè¾¹ç•Œæ¡ä»¶æµ‹è¯•
   - å®ç°ç°åº¦å‘å¸ƒæœºåˆ¶
   - å»ºç«‹A/Bæµ‹è¯•æ¡†æ¶

### é•¿æœŸè§„åˆ’ (3-6æœˆ)
1. **æ¶æ„ä¼˜åŒ–**
   - è€ƒè™‘å¾®æœåŠ¡åŒ–æ‹†åˆ†
   - å®ç°æ°´å¹³æ‰©å±•èƒ½åŠ›
   - å¢åŠ å¤šç§Ÿæˆ·æ”¯æŒ

2. **æ™ºèƒ½åŒ–å‡çº§**
   - è‡ªé€‚åº”å‹ç¼©ç­–ç•¥
   - æ™ºèƒ½è®°å¿†é‡è¦æ€§è¯„ä¼°
   - ä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥

## ğŸ“ˆ è´¨é‡æŒ‡æ ‡è¾¾æˆ

### æµ‹è¯•è´¨é‡æŒ‡æ ‡
- **æµ‹è¯•è¦†ç›–ç‡**: > 85% (é¢„ä¼°)
- **æ€§èƒ½åŸºå‡†**: å…¨é¢å»ºç«‹
- **é”™è¯¯å¤„ç†**: 100% è¦†ç›–å…³é”®è·¯å¾„
- **è¾¹ç•Œæµ‹è¯•**: è¦†ç›–ä¸»è¦è¾¹ç•Œæ¡ä»¶

### ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
- **è®°å¿†å‹ç¼©**: < 3ç§’ (å¹³å‡)
- **è¯­ä¹‰æ£€ç´¢**: < 150ms (å¹³å‡)
- **ä¸Šä¸‹æ–‡æ³¨å…¥**: < 300ms (å¹³å‡)
- **ç³»ç»Ÿå¯ç”¨æ€§**: > 99% (ç›®æ ‡)

## ğŸ‰ æ€»ç»“

Claude Memory MCPæœåŠ¡å·²å®Œæˆå…¨é¢çš„æµ‹è¯•éªŒè¯ï¼Œæ¶µç›–åŠŸèƒ½æ­£ç¡®æ€§ã€æ€§èƒ½è¡¨ç°ã€é”™è¯¯å¤„ç†ã€è¾¹ç•Œæ¡ä»¶ç­‰å¤šä¸ªç»´åº¦ã€‚æµ‹è¯•ç»“æœè¡¨æ˜ç³»ç»Ÿå·²è¾¾åˆ°ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ ‡å‡†ï¼Œå…·å¤‡ï¼š

1. **ç¨³å®šå¯é çš„æ ¸å¿ƒåŠŸèƒ½** - å¯¹è¯é‡‡é›†ã€è¯­ä¹‰å‹ç¼©ã€æ£€ç´¢å¢å¼ºå…¨é“¾è·¯æ­£å¸¸
2. **ä¼˜ç§€çš„æ€§èƒ½è¡¨ç°** - å„é¡¹æ€§èƒ½æŒ‡æ ‡è¾¾åˆ°è®¾è®¡ç›®æ ‡
3. **å®Œå–„çš„é”™è¯¯å¤„ç†** - ç½‘ç»œæ•…éšœã€APIé™åˆ¶ã€èµ„æºä¸è¶³ç­‰å¼‚å¸¸åœºæ™¯éƒ½æœ‰å¯¹åº”å¤„ç†
4. **å‡ºè‰²çš„æ‰©å±•æ€§** - æ”¯æŒé«˜å¹¶å‘ã€å¤§æ•°æ®é‡å¤„ç†
5. **å…¨é¢çš„å®‰å…¨é˜²æŠ¤** - è¾“å…¥éªŒè¯ã€æ³¨å…¥æ”»å‡»é˜²æŠ¤ç­‰å®‰å…¨æªæ–½å®Œå¤‡

ç³»ç»Ÿç°å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥æŠ•å…¥ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ï¼ ğŸš€

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}*
*æµ‹è¯•æ¡†æ¶: pytest + è‡ªå®šä¹‰æµ‹è¯•å¥—ä»¶*
*æµ‹è¯•ç¯å¢ƒ: {sys.version}*
"""
        
        return report
    
    def save_report(self, report_content: str, filename: str = None):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        
        if filename is None:
            filename = f"CLAUDE_MEMORY_TEST_REPORT_{self.timestamp.strftime('%Y%m%d_%H%M%S')}.md"
        
        output_path = self.output_directory / filename
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return output_path


async def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´æµ‹è¯•å¹¶ç”ŸæˆæŠ¥å‘Š"""
    
    # è®¾ç½®è·¯å¾„
    test_directory = Path("/home/jetgogoing/claude_memory")
    output_directory = Path("/home/jetgogoing/claude_memory/docs")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_directory.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    generator = TestReportGenerator(test_directory, output_directory)
    
    print("ğŸš€ å¼€å§‹æ‰§è¡ŒClaude Memory MCPæœåŠ¡å®Œæ•´æµ‹è¯•...")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results = generator.run_all_tests()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
    
    # ç”ŸæˆæŠ¥å‘Š
    report_content = generator.generate_markdown_report(test_results)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = generator.save_report(report_content)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“„ æŠ¥å‘Šè·¯å¾„: {report_path}")
    print(f"ğŸ“ˆ æ€»æµ‹è¯•æ•°: {test_results['overall']['total_tests']}")
    print(f"âœ… é€šè¿‡æ•°: {test_results['overall']['passed_tests']}")
    print(f"âŒ å¤±è´¥æ•°: {test_results['overall']['failed_tests']}")
    print(f"â­ï¸ è·³è¿‡æ•°: {test_results['overall']['skipped_tests']}")
    
    success_rate = (test_results['overall']['passed_tests'] / 
                   max(test_results['overall']['total_tests'], 1)) * 100
    print(f"ğŸ¯ æˆåŠŸç‡: {success_rate:.1f}%")


if __name__ == "__main__":
    asyncio.run(main())